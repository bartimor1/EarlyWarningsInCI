{
 "cells": [
  {
   "cell_type": "code",
   "id": "2899034c",
   "metadata": {},
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from cfg import config as cfg\n",
    "from pm4py.algo.evaluation.earth_mover_distance import algorithm as earth_mover_distance\n",
    "from lib.performance_analysis import extract_ef_performance, calc_output_rate, find_diff\n",
    "from lib.pre_processing import get_records\n",
    "from lib.utils import print_templates, export_log_to_csv, get_event_log, convert_to_interval_tree, extract_actions_from_paths, get_test_case_directory\n",
    "from lib.visualization import visualize_efg_w_freq, visualize_efg_w_duration, display_max_occurrences_in_case\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "simulation_mode = cfg.getboolean('Mode', 'simulation')\n",
    "is_preprocessing_needed = cfg.getboolean('Preprocessing', 'is_needed')"
   ],
   "id": "c19766bfc0c6bdf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pre-Processing",
   "id": "1e65a2ba9465fde"
  },
  {
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "cell_type": "code",
   "source": [
    "if is_preprocessing_needed:\n",
    "    if simulation_mode:  \n",
    "        scenario_group = \"7_no_degradations\"\n",
    "        base_test_case_folder = \"TC1_baseline_scenario\"\n",
    "        test_case_folder = \"TC30_no_degradation_different_seed\"\n",
    "        home_directory = \"Path/To/Test/Cases/Folder\"\n",
    "        log_testcases_folder = get_test_case_directory(home_directory, auto_detect=True)\n",
    "    else:\n",
    "        log_testcases_folder = \"Path/To/primary/folder/of/the/logs\"\n",
    "        base_log_folder = '1_883944'\n",
    "        after_change_log_folder = '2_874242'\n",
    "else:\n",
    "    #will be used for the results folder\n",
    "    log_testcases_folder = \"Path/To/primary/folder/of/the/logs\"\n",
    "    #should be in CSV format and include the following columns:timestamp, resource (component/module), req_id,\tmsg, pid (process pid if available),\tfunction, line\n",
    "    event_log_b = \"Path/To/Log\"\n",
    "    event_log_a = \"Path/To/Log\"\n",
    "    \n",
    "   \n"
   ],
   "id": "c4c14e9ef9db94b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if is_preprocessing_needed:\n",
    "    if simulation_mode:\n",
    "        event_log_path_b = os.path.join(log_testcases_folder, scenario_group, base_test_case_folder)       \n",
    "        event_log_path_a = os.path.join(log_testcases_folder, scenario_group, test_case_folder)\n",
    "        filename_b = [filename for filename in os.listdir(event_log_path_b) if filename.endswith('.log')][0]\n",
    "        filename_a = [filename for filename in os.listdir(event_log_path_a) if filename.endswith('.log')][0]\n",
    "        raw_event_log_b = os.path.join(event_log_path_b, filename_b)\n",
    "        event_log_b = os.path.join(event_log_path_b,filename_b.replace('.log', '.csv'))\n",
    "        raw_event_log_a = os.path.join(event_log_path_a, filename_a)\n",
    "        event_log_a = os.path.join(event_log_path_a, filename_b.replace('.log', '.csv'))\n",
    "    else: \n",
    "        event_log_path_b = os.path.join(log_testcases_folder,base_log_folder)\n",
    "        event_log_path_a = os.path.join(log_testcases_folder, after_change_log_folder)\n",
    "        raw_event_log_b = os.path.join(event_log_path_b, 'screen-g-api.txt')\n",
    "        event_log_b = os.path.join(event_log_path_b,'event_log_base.csv')\n",
    "        raw_event_log_a = os.path.join(event_log_path_a, 'screen-g-api.txt')\n",
    "        event_log_a = os.path.join(event_log_path_a, 'event_log_after_change.csv')\n",
    "            \n",
    "    # remove files if exist:\n",
    "    for file in [event_log_b, event_log_a]:\n",
    "        if os.path.isfile(file):\n",
    "            os.remove(file)\n",
    "    \n",
    "    # analyze event log before commit\n",
    "    with open(raw_event_log_b, \"r\") as fh:\n",
    "        records_b, used_templates_b, changed_templates_b, templates_to_records_b = get_records(fh, [])        \n",
    "        print(f\"Base event log contains {len(records_b)} records, {len(used_templates_b)} recorded activities\")\n",
    "        \n",
    "    \n",
    "    with open(raw_event_log_a, \"r\") as fh:\n",
    "        records_a, used_templates_a, changed_templates_a, templates_to_records_a = get_records(fh, used_templates_b)        \n",
    "        print(f\"Event log after code change contains {len(records_a)} records, {len(used_templates_a)} recorded activities\")\n",
    "        \n",
    "    export_log_to_csv(records_b, event_log_b, True)\n",
    "    export_log_to_csv(records_a, event_log_a, True)\n"
   ],
   "id": "21d2a449",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Detect Performance Degradations ",
   "id": "5cb774319d504e40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<span style=\"color:green;font-size:24px\">**Extract EFRs from CSV logs**</span> ",
   "id": "879ab403"
  },
  {
   "cell_type": "code",
   "id": "106f0225",
   "metadata": {},
   "source": [
    "method_start_time=datetime.now()\n",
    "#read CSV files\n",
    "csv_df_before, event_log_before = get_event_log(event_log_b)\n",
    "csv_df_after, event_log_after = get_event_log(event_log_a)\n",
    "\n",
    "#extract EFRs\n",
    "efg_b = pm4py.discover_eventually_follows_graph(event_log_before, activity_key='concept:name', case_id_key='case:concept:name', timestamp_key='time:timestamp')\n",
    "efg_a = pm4py.discover_eventually_follows_graph(event_log_after, activity_key='concept:name', case_id_key='case:concept:name', timestamp_key='time:timestamp')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "513adef7",
   "metadata": {},
   "source": [
    "visualize = cfg.getboolean('Visualization', 'visualize')\n",
    "if visualize:\n",
    "    visualize_efg_w_freq(efg_b)\n",
    "    visualize_efg_w_freq(efg_a)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "999f2d48",
   "metadata": {},
   "source": "<span style=\"color:green;font-size:24px\">**Extract EFRs performance and variants**</span> "
  },
  {
   "cell_type": "code",
   "id": "25d9e8d0",
   "metadata": {},
   "source": [
    "ef_pairs_b, variants_dfg_b = extract_ef_performance(efg_b, event_log_before)\n",
    "ef_pairs_a, variants_dfg_a = extract_ef_performance(efg_a, event_log_after)\n",
    "\n",
    "if visualize:\n",
    "    visualize_efg_w_duration(ef_pairs_b)\n",
    "    visualize_efg_w_duration(ef_pairs_a)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<span style=\"color:green;font-size:24px\">**Find degradations by comparing EFRs duration**</span> ",
   "id": "e4fe959dc1e34027"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "threshold = cfg.getfloat('Detect', 'threshold')\n",
    "degradation_dict, improvement_dict = find_diff(ef_pairs_b, ef_pairs_a, variants_dfg_b, variants_dfg_a, threshold=threshold, print_head=5, visualize=visualize)\n"
   ],
   "id": "8b892ee4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "# If no degradation found, exit\n",
    "if len(degradation_dict) == 0:\n",
    "    folder, first_case = os.path.split(event_log_path_b)\n",
    "    second_case = os.path.split(event_log_path_a)[-1]\n",
    "    res_path = os.path.join(folder, \"Results\") \n",
    "    if not os.path.isdir(res_path):\n",
    "        os.mkdir(res_path)\n",
    "    with open(os.path.join(res_path, f\"RES_{first_case}_{second_case}.txt\"), \"w\") as fh:\n",
    "        fh.write(f\"====Classification====\\n\")\n",
    "        fh.write('No degradations found')\n",
    "    raise StopExecution"
   ],
   "id": "6a13debe3f44c095",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analyze sources for degradation",
   "id": "1211e3a3f276f006"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<span style=\"color:green;font-size:24px\">**Extract activities that may affect the degradation**</span>",
   "id": "ac995e71a085eb71"
  },
  {
   "cell_type": "code",
   "id": "6a88f60b",
   "metadata": {},
   "source": [
    "#Extract all actions in the degraded paths\n",
    "degraded_paths = dict(sorted(degradation_dict.items(), key=lambda item: item[1][\"diff\"], reverse=True)).keys()\n",
    "export_degradations = cfg.getboolean('Export', 'degraded_paths_xes')\n",
    "degradation_actions_b = extract_actions_from_paths(degraded_paths, event_log_before, event_log_path_b, export_degradations, \"degraded_\")\n",
    "degradation_actions_a = extract_actions_from_paths(degraded_paths, event_log_after, event_log_path_a, export_degradations, \"degraded_\")\n",
    "\n",
    "degradation_actions = degradation_actions_b | degradation_actions_a"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Extract all actions in the improved paths\n",
    "improved_paths = dict(sorted(improvement_dict.items(), key=lambda item: item[1][\"diff\"], reverse=True)).keys()\n",
    "export_improvements = cfg.getboolean('Export', 'improved_paths_xes')\n",
    "improvement_actions_b = extract_actions_from_paths(improved_paths, event_log_before, event_log_path_b, export_improvements, \"improved_\")\n",
    "improvement_actions_a = extract_actions_from_paths(improved_paths, event_log_after, event_log_path_a, export_improvements, \"improved_\")\n",
    "\n",
    "improvement_actions = improvement_actions_b | improvement_actions_a"
   ],
   "id": "e562becb46091bd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<span style=\"color:green;font-size:24px\">**Convert to interval tree**</span>",
   "id": "85efcc2f"
  },
  {
   "cell_type": "code",
   "id": "d04333d8",
   "metadata": {},
   "source": [
    "#Extract logs into interval tree for accumulated work queues identifications \n",
    "interval_step = cfg.getint('Metric', 'period')\n",
    "df_before, intervals_before = convert_to_interval_tree(event_log_before, used_templates_b, interval_step=interval_step, print_head=None)\n",
    "df_after, intervals_after = convert_to_interval_tree(event_log_after, used_templates_a, interval_step=interval_step, print_head=None)\n",
    "system_cases_before = len(event_log_before.groupby(['case_id']).size())\n",
    "system_rate_before = system_cases_before/len(intervals_before)\n",
    "print(f\"system before, TP rate:{system_rate_before}, Num of cases:{system_cases_before}, intervals before:{len(intervals_before)}\")\n",
    "system_cases_after = len(event_log_after.groupby(['case_id']).size())\n",
    "system_rate_after = system_cases_after/len(intervals_after)\n",
    "print(f\"system after, TP rate:{system_rate_after}, Num of cases:{system_cases_after}, intervals after:{len(intervals_after)}\")\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f546a2b9",
   "metadata": {},
   "source": "<span style=\"color:green;font-size:24px\">**Calculate metrics**</span>"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Padd df_before with index's that appear only in the df_after (newly introduced actions)\n",
    "actions_only_in_df_after = [idx for idx in df_after.index if idx not in df_before.index]\n",
    "df_before=pd.concat([df_before, pd.Series(index=actions_only_in_df_after)], axis=0).fillna(0)\n",
    "\n",
    "#Padd df_after with index's that appear only in the df_before (removed actions)\n",
    "actions_only_in_df_before = [idx for idx in df_before.index if idx not in df_after.index]\n",
    "df_after=pd.concat([df_after, pd.Series(index=actions_only_in_df_before)], axis=0).fillna(0)\n",
    "\n",
    "observed_actions = degradation_actions | improvement_actions\n",
    "df_output_b = calc_output_rate(observed_actions, intervals_before, df_before, event_log_before, suffix=\"v1\")\n",
    "df_output_a = calc_output_rate(observed_actions, intervals_after, df_after, event_log_after, suffix=\"v2\")\n",
    "\n",
    "# concatenate mesures of the two versions \n",
    "df_output_rate = pd.concat([df_output_b, df_output_a], axis=1)\n",
    "\n"
   ],
   "id": "159832ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0ffd860d",
   "metadata": {},
   "source": "<span style=\"color:green;font-size:24px\">**Calculate difference in metrics between software versions**</span>"
  },
  {
   "cell_type": "code",
   "id": "1a50e2a5",
   "metadata": {},
   "source": [
    "# Check Frequency trend\n",
    "df_output_rate['Freq Diff'] = (df_output_rate['absolute freq v2'].astype(float) - df_output_rate['absolute freq v1'].astype(float))/ df_output_rate['absolute freq v1'].astype(float) \n",
    "\n",
    "# Check queue trend\n",
    "df_output_rate['Max Queue Diff'] = (df_output_rate['max queue v2'].astype(float) - df_output_rate['max queue v1'].astype(float))/ df_output_rate['max queue v1'].astype(float)\n",
    "# On the flow start activities, we cannot measure queue since there is not preceding\n",
    "df_output_rate['Max Queue Diff'].fillna(0, inplace=True)\n",
    "\n",
    "# Check TP trend\n",
    "df_output_rate['TP Diff'] = (df_output_rate['TP rate v2'].astype(float) - df_output_rate['TP rate v1'].astype(float))/ df_output_rate['TP rate v1'].astype(float)\n",
    "#in case that 'TP Rate v1' is 0, the above will cause na in the TP Diff\n",
    "df_output_rate.loc[df_output_rate['TP Diff'].isna(), 'TP Diff'] = df_output_rate['TP rate v2']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<span style=\"color:green;font-size:24px\">**Add max occurrences in case metric**</span>",
   "id": "32a33b75435831c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "activity_counts_v1 = event_log_before.groupby(['case_id', 'msg']).size().reset_index(name='count')\n",
    "msg_stats_v1 = activity_counts_v1.groupby('msg')['count'].agg(['max', 'mean', 'median'])\n",
    "msg_stats_v1['mean'] = msg_stats_v1['mean'].round(2)\n",
    "msg_stats_v1 = msg_stats_v1[msg_stats_v1.index.isin(observed_actions)]\n",
    "msg_stats_v1['Version'] = 'v1'\n",
    "df_output_rate['max occurrences in case v1'] = msg_stats_v1['max']\n",
    "# fill 0 were activities belongs only to the other log \n",
    "df_output_rate['max occurrences in case v1'].fillna(0, inplace=True)\n",
    "\n",
    "activity_counts_v2 = event_log_after.groupby(['case_id', 'msg']).size().reset_index(name='count')\n",
    "msg_stats_v2 = activity_counts_v2.groupby('msg')['count'].agg(['max', 'mean', 'median'])\n",
    "msg_stats_v2['mean'] = msg_stats_v2['mean'].round(2)\n",
    "msg_stats_v2 = msg_stats_v2[msg_stats_v2.index.isin(observed_actions)]\n",
    "msg_stats_v2['Version'] = 'v2'\n",
    "df_output_rate['max occurrences in case v2'] = msg_stats_v2['max']\n",
    "# fill 0 were activities belongs only to the other log\n",
    "df_output_rate['max occurrences in case v2'].fillna(0, inplace=True)\n",
    "\n",
    "df_output_rate['Max Occurrences In Case Diff'] = (df_output_rate['max occurrences in case v2'].astype(float) - df_output_rate['max occurrences in case v1'].astype(float))/df_output_rate['max occurrences in case v1'].astype(float)\n",
    "\n",
    "if visualize:\n",
    "    display_max_occurrences_in_case(msg_stats_v1, msg_stats_v2)\n"
   ],
   "id": "2548f1f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculate Earth Movers Distance",
   "id": "7c7de2e7cf9260d7"
  },
  {
   "cell_type": "markdown",
   "id": "6b419932",
   "metadata": {},
   "source": [
    "### log before - log after"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "emd_dict = defaultdict(list)\n",
    "efr_for_analysis = defaultdict(set)\n",
    "\n",
    "for efr in (ef_pairs_a.keys() | ef_pairs_b.keys()):\n",
    "    if efr[1] in observed_actions:\n",
    "        efr_for_analysis[efr[1]].add(efr)\n",
    "emd_dict = defaultdict(list)\n",
    "\n",
    "for activity, preceedings in efr_for_analysis.items():\n",
    "    filtered_db_b = pm4py.filtering.filter_eventually_follows_relation(event_log_before, preceedings)\n",
    "    filtered_event_log_b = pm4py.format_dataframe(filtered_db_b, case_id='case_id', activity_key='msg', timestamp_key='timestamp')\n",
    "    language_b = pm4py.get_stochastic_language(filtered_event_log_b)\n",
    "\n",
    "    filtered_db_a = pm4py.filtering.filter_eventually_follows_relation(event_log_after, preceedings)\n",
    "    filtered_event_log_a = pm4py.format_dataframe(filtered_db_a, case_id='case_id', activity_key='msg', timestamp_key='timestamp')\n",
    "    language_a = pm4py.get_stochastic_language(filtered_event_log_a)\n",
    "\n",
    "    emd_log2log = earth_mover_distance.apply(language_b, language_a)\n",
    "    emd_dict['StartActivities'].append(preceedings)\n",
    "    emd_dict['EndActivity'].append(activity)\n",
    "    emd_dict['EMD'].append(emd_log2log)\n",
    "\n",
    "df_emd = pd.DataFrame(emd_dict)\n",
    "df_emd.set_index('EndActivity', inplace=True)\n",
    "df_output_rate['Earth Movers Distance'] =df_emd['EMD']\n",
    "#On the start activity of the flow, we cannot measure distance since there is not preceding\n",
    "df_output_rate['Earth Movers Distance'].fillna(0, inplace=True)"
   ],
   "id": "b8737047",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Classification",
   "id": "ca40eb844d925fc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "classifications = pd.DataFrame(False, index=df_output_rate.index, columns=[\"Control Flow Change\", \"Retry Pattern\", \"Over-performing\", \"Under-performing\"]) ",
   "id": "9ab1e90a0e262c2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Path changes classification",
   "id": "5ed737c6209b35d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "classifications[\"Control Flow Change\"] = df_output_rate['Earth Movers Distance']>=cfg.getfloat('Classification', 'emd_threshold')",
   "id": "69480ae58937c74e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retry",
   "id": "cffc2d81badc2005"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "classifications[\"Retry Pattern\"] = df_output_rate['Max Occurrences In Case Diff']>=cfg.getfloat('Classification', 'max_occur_threshold')",
   "id": "b176ba000911801c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Over and Under performing",
   "id": "408f2930051085ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classifications[\"Under-performing\"] = ((df_output_rate['TP Diff']<=cfg.getfloat('Classification', 'under_performing_threshold') )& (df_output_rate['Max Queue Diff']>=cfg.getfloat('Classification', 'degradation_queue_threshold'))) \n",
    "classifications[\"Over-performing\"] = ((df_output_rate['TP Diff']>=cfg.getfloat('Classification', 'over_performing_threshold') )& (df_output_rate['Max Queue Diff']<=cfg.getfloat('Classification', 'improvement_queue_threshold'))) "
   ],
   "id": "3108ac8811d588f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res_df = classifications[(\n",
    "    (classifications['Control Flow Change']==True) |\n",
    "    (classifications['Retry Pattern']==True) |\n",
    "    (classifications['Under-performing']==True) |\n",
    "    (classifications['Over-performing']==True) \n",
    ")]\n"
   ],
   "id": "a3715380d6170883",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Prioritizing source for degradation",
   "id": "4867d112d737d0b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classification = defaultdict(list)\n",
    "sources = []\n",
    "retry_src = classifications.index[classifications['Retry Pattern'] == True].tolist()\n",
    "path_change_src = classifications.index[classifications['Control Flow Change'] == True].tolist()\n",
    "underperform_src = classifications.index[classifications['Under-performing'] == True].tolist()\n",
    "overperform_src = classifications.index[classifications['Over-performing'] == True].tolist()\n",
    "intersection = set(retry_src) & set(path_change_src)\n",
    "\n",
    "\n",
    "# when new activity introduced, the max occurrences in case diff will raise\n",
    "if intersection:\n",
    "    for item in intersection:\n",
    "        if item in actions_only_in_df_after:\n",
    "            classification['Control Flow Change'].append(item)\n",
    "            retry_src.remove(item) \n",
    "# Classify Retry\n",
    "if retry_src:\n",
    "    for item in retry_src:\n",
    "        classification['Retry Pattern'].append(item)\n",
    "# Classify Path Change \n",
    "elif path_change_src:\n",
    "    for item in path_change_src:\n",
    "        classification['Control Flow Change'].append(item)\n",
    "# Classify over-performing and under-performing\n",
    "else:\n",
    "    if any([overperform_src, underperform_src]):\n",
    "        for item in overperform_src:\n",
    "            classification['Over-performing'].append(item)\n",
    "        for item in underperform_src:\n",
    "            classification['Under-performing'].append(item)\n",
    "    else:\n",
    "        classification['Results'].append(\"No degradation Found\")\n"
   ],
   "id": "eb14c4c1127f2992",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Write results report",
   "id": "3495b248c9e5fcc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "method_end_time=datetime.now()\n",
    "folder, first_case = os.path.split(event_log_path_b)\n",
    "second_case = os.path.split(event_log_path_a)[-1]\n",
    "res_path = os.path.join(folder, \"Results\") \n",
    "if not os.path.isdir(res_path):\n",
    "    os.mkdir(res_path)\n",
    "    \n",
    "with open(os.path.join(res_path, f\"RES_{first_case}_{second_case}.txt\"), \"w\") as fh:\n",
    "    fh.write(f\"====Classification====\\n\")\n",
    "    for k,v in classification.items():\n",
    "        fh.write(f\"{k}:  {set(v)}\\n\")\n",
    "    fh.write(\"\\n\\n\")\n",
    "    fh.write(\"================================\\n\")\n",
    "    fh.write(\"==== Additional Information ====\\n\")\n",
    "    fh.write(\"================================\\n\")\n",
    "    print_templates(used_templates_b, prefix=\"V1\", fh=fh)\n",
    "    print_templates(used_templates_a, prefix=\"V2\", fh=fh)\n",
    "    fh.write(f\"\\n\\n====Activities Metrics====\\n\")\n",
    "    fh.write(df_output_rate.to_string(header=True, index=True))\n",
    "    fh.write(f\"\\n\\n====source activities====\\n\")\n",
    "    fh.write(res_df.to_string(header=True, index=True))\n",
    "    fh.write(f\"\\n\\n====Summary====\\n\")\n",
    "    fh.write(f\"Cases before: {system_cases_before}\\n\")\n",
    "    fh.write(f\"Cases After: {system_cases_after}\\n\")\n",
    "    fh.write(f\"Intervals before:{len(intervals_before)}\\n\")\n",
    "    fh.write(f\"Intervals after:{len(intervals_after)}\\n\")\n",
    "    fh.write(f\"EF detected degradations:{len(degradation_dict)}\\n\")\n",
    "    fh.write(f\"Number of observed activities:{len(observed_actions)}\\n\")\n",
    "    fh.write(f\"Retry Patterns:{len(retry_src)}\\n\")\n",
    "    fh.write(f\"Control Flow:{len(path_change_src)}\\n\")\n",
    "    fh.write(f\"Overperforming:{len(overperform_src)}\\n\")\n",
    "    fh.write(f\"Underperforming:{len(underperform_src)}\\n\")\n",
    "    fh.write(f\"Method time:{method_end_time-method_start_time}\\n\")\n",
    "    \n",
    "    source_activities = set(retry_src) | set(path_change_src) | set(overperform_src) | set(underperform_src)\n",
    "    ef_counters = defaultdict(int)\n",
    "    \n",
    "    for ef in degradation_dict:\n",
    "        for variant in variants_dfg_a[ef]:\n",
    "            ef_path= variant[3]\n",
    "            for activity in ef_path:    \n",
    "                if activity in source_activities:\n",
    "                    ef_counters[ef] += 1\n",
    "                    break    \n",
    "    fh.write(f\"Total degraded EFs involve source activity: {len(ef_counters)}/{len(degradation_dict)} ({len(ef_counters)/len(degradation_dict)*100:.2f}%)\\n\")\n",
    "    \n",
    "    ef_counters = defaultdict(int)\n",
    "    for ef in improvement_dict:\n",
    "        for variant in variants_dfg_a[ef]:\n",
    "            ef_path= variant[3]\n",
    "            for activity in ef_path:    \n",
    "                if activity in source_activities:\n",
    "                    ef_counters[ef] += 1\n",
    "                    break    \n",
    "    fh.write(f\"Total improved EFs involve source activity: {len(ef_counters)}/{len(improvement_dict)} ({len(ef_counters)/len(improvement_dict)*100:.2f}%)\\n\")\n",
    "    "
   ],
   "id": "5985f271db01b3a1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
